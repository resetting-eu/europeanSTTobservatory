{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "from hugchat import hugchat\n",
    "from hugchat.login import Login\n",
    "from hugchat.exceptions import ChatError\n",
    "import urllib.error\n",
    "\n",
    "# The path of each catalog\n",
    "segittur_2022 = \"../Catalogs/Segittur/catalog_segittur_2022.json\"\n",
    "segittur_2023 = \"../Catalogs/Segittur/catalog_segittur_2023.json\"\n",
    "adestic_v1 = \"../Catalogs/Adestic/catalogo_soluciones_turisticas_V1.json\"\n",
    "adestic_v2 = \"../Catalogs/Adestic/catalogo_soluciones_turisticas_V2.json\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T09:57:14.483987500Z",
     "start_time": "2024-03-06T09:57:14.094117500Z"
    }
   },
   "id": "cda5d97c9a2237e2"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\"\"\" It will transform and reduce the content of the catalog json file to a JSON object where each key is a \n",
    "solution name and value is a dictionary with the company, product description, page and solution types. \n",
    "In addition, all html tags are removed. This way, it's easier to search for repeats. \n",
    "An example: \n",
    "\"COUNTING PEOPLE ON BUSES USING ARTIFICIAL INTELLIGENCE\": {\n",
    "    \"company\": \"ABACO INGENIERIA Y SEGURIDAD\",\n",
    "    \"product_description\": \"...\",\n",
    "    \"page\": 10,\n",
    "    \"solType\": [\n",
    "        \"Security/Blockchain/Capacity control\"\n",
    "    ]\n",
    "}\n",
    "The parameter isAdestic needs to be True when the catalog is from Adestic, to remove the part of the solution name \n",
    "\"(Original name (Spanish) ...)\"\n",
    "\"\"\"\n",
    "def extract_info_to_analyze_repetitions(file, isAdestic=False):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        solutions = {}\n",
    "\n",
    "        for company in data['companies']:\n",
    "            if re.search('<.*?>', company):\n",
    "                soup = BeautifulSoup(company, 'html.parser')\n",
    "                # print(json.dumps(company, indent=4))\n",
    "                company_name = soup.h2.text\n",
    "            else:\n",
    "                company_name = company\n",
    "                \n",
    "            if re.search('<.*?>', data['companies'][company]['company_url']):\n",
    "                company_url= re.sub('<.*?>', '', data['companies'][company]['company_url'])\n",
    "            else:\n",
    "                company_url = data['companies'][company]['company_url']\n",
    "\n",
    "            for solution in data['companies'][company]['products']:\n",
    "                if re.search('<.*?>', solution['product_name']):\n",
    "                    soup = BeautifulSoup(solution['product_name'], 'html.parser')\n",
    "                    solution_name = soup.h1.text\n",
    "                else:\n",
    "                    solution_name = solution['product_name']\n",
    "                    \n",
    "                if re.search('<.*?>', solution['product_description']):\n",
    "                    solution_description = re.sub('<.*?>', '', solution['product_description'])\n",
    "\n",
    "                if isAdestic:\n",
    "                    solution_name = solution_name.split('(Original name (Spanish)')[0].strip()\n",
    "\n",
    "                if type(solution['solType']) is list:\n",
    "                    sol_types = solution['solType']\n",
    "                else:\n",
    "                    soup = BeautifulSoup(solution['solType'], 'html.parser')\n",
    "                    sol_types = [li.text for li in soup.find_all('li')]\n",
    "                    \n",
    "                page_number = solution['page']\n",
    "\n",
    "                solutions[solution_name] = {\n",
    "                    \"company\": company_name.strip(),\n",
    "                    \"company_url\": company_url.replace(\"www.\",\"\"),\n",
    "                    \"product_description\": solution_description,\n",
    "                    \"page\": page_number,\n",
    "                    \"solType\": sol_types\n",
    "                }\n",
    "    with open(f\"Small Versions/Small_Version_{os.path.basename(file)}\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(json.dumps(solutions, indent=4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T12:58:43.656691700Z",
     "start_time": "2024-03-05T12:58:43.614106Z"
    }
   },
   "id": "b80ed626f8f85285"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Uncomment the lines below to run the function with each catalog and with isAdestic=True for the Adestic catalogs\n",
    "# extract_info_to_analyze_repetitions(adestic_v1, True)\n",
    "# extract_info_to_analyze_repetitions(adestic_v2, True)\n",
    "# extract_info_to_analyze_repetitions(segittur_2022)\n",
    "# extract_info_to_analyze_repetitions(segittur_2023)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T12:58:50.520723500Z",
     "start_time": "2024-03-05T12:58:49.780301800Z"
    }
   },
   "id": "4a497dc3c8de65a0"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# The path of each small version of the catalog resulting from the function extract_info_to_analyze_repetitions\n",
    "small_segittur_2022 = \"Small Versions/Small_Version_catalog_segittur_2022.json\"\n",
    "small_segittur_2023 = \"Small Versions/Small_Version_catalog_segittur_2023.json\"\n",
    "small_adestic_v1 = \"Small Versions/Small_Version_catalogo_soluciones_turisticas_V1.json\"\n",
    "small_adestic_v2 = \"Small Versions/Small_Version_catalogo_soluciones_turisticas_V2.json\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T09:57:14.506011500Z",
     "start_time": "2024-03-06T09:57:14.483987500Z"
    }
   },
   "id": "2b7df79a2f5c6a"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\"\"\" Some solution types in the json files don't have the correct solution type name. This function will check \n",
    "if the solution type exists in the Type_of_Solution_Association (EN).json file (which contains the equivalent \n",
    "solution types among the catalogs). If doesn't exist, it will be added to a list of incorrect solution types. \n",
    "Then, a manual correction is necessary. For each incorrect type identified you have to associate the \n",
    "right type.\"\"\"\n",
    "# def check_if_type_exists(catalog, sol_types, sol_type):\n",
    "#     for t in sol_types:\n",
    "#         if (isinstance(t[catalog], list) and sol_type in t[catalog]) or (isinstance(t[catalog], str) and sol_type == t[catalog]):\n",
    "#             return True\n",
    "#     return False\n",
    "# \n",
    "# def check_for_incorrect_sol_types(catalog, solutions_file):\n",
    "#     with open(solutions_file, 'r', encoding='utf-8') as f:\n",
    "#         solutions = json.load(f)\n",
    "#     with open(\"Type_of_Solution_Association (EN).json\", 'r', encoding='utf-8') as f:\n",
    "#         sol_types = json.load(f)\n",
    "#         \n",
    "#     incorrect_sol_types = []\n",
    "#         \n",
    "#     for sol in solutions.keys():\n",
    "#         for t in solutions[sol]['solType']:\n",
    "#             # print(f\"{t}, {not check_if_type_exists(catalog, sol_types, t)}, {t not in incorrect_sol_types}\")\n",
    "#             if not check_if_type_exists(catalog, sol_types, t) and t not in incorrect_sol_types:\n",
    "#                 incorrect_sol_types.append(t)\n",
    "#     \n",
    "#     with open(f\"Small Versions/Incorrect_Sol_Types_{catalog}_Without_Correction.json\", \"w\", encoding='utf-8') as f:\n",
    "#         # print(f\"Writing...\\n{json.dumps(incorrect_sol_types, indent=4)}\")\n",
    "#         f.write(json.dumps(incorrect_sol_types, indent=4))\n",
    "                \n",
    "\"\"\" This function needs to be updated \"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T10:57:41.666904500Z",
     "start_time": "2024-03-04T10:57:41.630376500Z"
    }
   },
   "id": "e0187e3fec1daf94"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Uncomment the lines below to run the function for each catalog\n",
    "# check_for_incorrect_sol_types(\"Segittur 2022\", small_segittur_2022)\n",
    "# check_for_incorrect_sol_types(\"Segittur 2023\", small_segittur_2023)\n",
    "# check_for_incorrect_sol_types(\"Adestic V1\", small_adestic_v1)\n",
    "# check_for_incorrect_sol_types(\"Adestic V2\", small_adestic_v2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T10:58:11.157028700Z",
     "start_time": "2024-03-04T10:58:11.109706Z"
    }
   },
   "id": "f13ecdfc7a6416b"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# After manually correcting the incorrect solution types, the small versions json file is corrected\n",
    "\n",
    "def correct_sol_types(catalog, incorrect_types_file):\n",
    "    with open(catalog, 'r', encoding='utf-8') as f:\n",
    "        data_catalog = json.load(f)\n",
    "        \n",
    "        with open(incorrect_types_file, 'r', encoding='utf-8') as i:\n",
    "            incorrect_types = json.load(i)\n",
    "            \n",
    "            for sol in data_catalog.keys():\n",
    "                fixed_sol_types = []\n",
    "                for t in data_catalog[sol]['solType']:\n",
    "                    if t in incorrect_types:\n",
    "                        fixed_sol_types.append(incorrect_types[t])\n",
    "                    else:\n",
    "                        fixed_sol_types.append(t)\n",
    "                data_catalog[sol]['solType'] = fixed_sol_types\n",
    "                        \n",
    "    with open(catalog, 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(data_catalog, indent=4))\n",
    "#         \n",
    "# correct_sol_types(small_segittur_2022, \"Small Versions/Incorrect_Sol_Types_Segittur 2022.json\")\n",
    "# correct_sol_types(small_adestic_v1, \"Small Versions/Incorrect_Sol_Types_Adestic V1.json\")\n",
    "# correct_sol_types(small_adestic_v2, \"Small Versions/Incorrect_Sol_Types_Adestic V2.json\")\n",
    "#     "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T12:59:14.863596100Z",
     "start_time": "2024-03-05T12:59:14.823070100Z"
    }
   },
   "id": "dcbfbdb9bb088a1f"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# The json objects of the small versions of the catalogs\n",
    "sol_segittur_2022 = json.load(open(small_segittur_2022, 'r', encoding='utf-8'))\n",
    "sol_segittur_2023 = json.load(open(small_segittur_2023, 'r', encoding='utf-8'))\n",
    "sol_adestic_v1 = json.load(open(small_adestic_v1, 'r', encoding='utf-8'))\n",
    "sol_adestic_v2 = json.load(open(small_adestic_v2, 'r', encoding='utf-8'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T11:41:32.255730100Z",
     "start_time": "2024-03-06T11:41:32.205748800Z"
    }
   },
   "id": "2fa2ad1563d6c739"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "cookie_path_dir = \"../cookies\"\n",
    "\n",
    "login_path = \"C:\\\\Users\\Diogo Cosme\\Documents\\ISCTE\\Tese\\huggingFace login.json\"\n",
    "login_path = login_path.replace(\"\\\\\", \"/\") \n",
    "login_info = json.load(open(login_path, 'r'))\n",
    "\"\"\" If Login hasn't been done before\"\"\"\n",
    "# sign = Login(login_info['email'], login_info['password'])\n",
    "# cookies = sign.login(cookie_dir_path=cookie_path_dir, save_cookies=True)\n",
    "# cookies_dict = cookies.get_dict()\n",
    "\n",
    "\"\"\" If Login has been done before, replace the path below with your cookies json file path \"\"\"\n",
    "cookies_dict = json.load(open(f\"{cookie_path_dir}/{login_info['email']}.json\", 'r'))\n",
    "\n",
    "\"\"\" This will create a new conversation \"\"\"\n",
    "chatbot = hugchat.ChatBot(cookies=cookies_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T09:57:15.660727900Z",
     "start_time": "2024-03-06T09:57:14.583894Z"
    }
   },
   "id": "6f2380f12ab87041"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def check_if_solutions_were_already_added_to_repetitions(solution1, catalog1, solution2, catalog2, company_url, repeated_solutions):\n",
    "    solution1_added, solution2_added = False, False\n",
    "    index = -1\n",
    "    for i, repetition in enumerate(repeated_solutions):\n",
    "        if repetition['company_url'] == company_url:\n",
    "            if catalog1 in repetition and any(sol['solution'] == solution1 for sol in repetition[catalog1]):\n",
    "                solution1_added = True\n",
    "            if catalog2 in repetition and any(sol['solution'] == solution2 for sol in repetition[catalog2]):\n",
    "                solution2_added = True\n",
    "            if solution1_added or solution2_added:\n",
    "                index = i\n",
    "                break\n",
    "    return solution1_added, solution2_added, index\n",
    "\n",
    "def create_json_object_to_repeated_solution(name, page):\n",
    "    return {\n",
    "        \"solution\": name,\n",
    "        \"page\": page\n",
    "    }\n",
    "    \n",
    "\"\"\" Everytime a repeated solution is identified, it will be added to the repeated_solutions dictionary. \n",
    "The key is the solution name and the value is a dictionary with the company, the solution page number in \n",
    "each catalog, and the method by which it was identified. Either by comparing by solution and company \n",
    "names or through LLMs.\"\"\"\n",
    "def add_repeated_solution(solution, repeated_solutions, catalog_name, solution_data, other_catalog_name, other_solution_name, other_solution_data, method):\n",
    "    solution_added, other_solution_added, index = check_if_solutions_were_already_added_to_repetitions(solution, catalog_name, other_solution_name, other_catalog_name, solution_data['company_url'], repeated_solutions)\n",
    "    \n",
    "    if method == 'LLM':\n",
    "        print(f\"\\n{solution} vs {other_solution_name}\\nSolution Added: {solution_added}; Other Solution Added: {other_solution_added}; Index: {index}\")\n",
    "    \n",
    "    if index == -1:\n",
    "        repeated_solutions.append({\n",
    "            \"company_url\": solution_data['company_url'],\n",
    "            \"methods\": [method]\n",
    "        })\n",
    "        index = len(repeated_solutions) - 1\n",
    "    \n",
    "    if not solution_added:\n",
    "        solution_json = create_json_object_to_repeated_solution(solution, solution_data['page'])\n",
    "        if catalog_name not in repeated_solutions[index]:\n",
    "            repeated_solutions[index][catalog_name] = [solution_json]\n",
    "        else:\n",
    "            repeated_solutions[index][catalog_name].append(solution_json)\n",
    "        \n",
    "    if not other_solution_added:\n",
    "        other_solution_json = create_json_object_to_repeated_solution(other_solution_name, other_solution_data['page'])\n",
    "        if other_catalog_name not in repeated_solutions[index]:\n",
    "            repeated_solutions[index][other_catalog_name] = [other_solution_json]\n",
    "        else:\n",
    "            repeated_solutions[index][other_catalog_name].append(other_solution_json)\n",
    "    \n",
    "    if method not in repeated_solutions[index]['methods']:\n",
    "        repeated_solutions[index]['methods'].append(method)\n",
    "    return repeated_solutions\n",
    "\n",
    "\"\"\"Everytime a solution is identified as not being a repetition by the LLM, it will be added to the \n",
    "false_repetitions dictionary. The key is the solution name and the value is a dictionary with the \n",
    "company, the solution page number in the respective catalog, and the other solutions with which it \n",
    "was compared. Is only relevant to check that the comparison from LLMs is working correctly.\"\"\"\n",
    "def add_false_repetitions(solution_name, solution_data, false_repetition_name, false_repetition_data, false_repetitions, catalog_name, other_catalog_name):\n",
    "    if solution_name not in false_repetitions:\n",
    "        false_repetitions[solution_name] = {\n",
    "            catalog_name: solution_data['page'],\n",
    "            \"others_solutions\": [{\n",
    "                \"other_solution\": false_repetition_name,\n",
    "                other_catalog_name: false_repetition_data['page']\n",
    "            }]\n",
    "        }\n",
    "    else:\n",
    "        # print(json.dumps(false_repetitions[solution_name], indent=4))\n",
    "        already_added = False\n",
    "        for other in false_repetitions[solution_name][\"others_solutions\"]:\n",
    "            if other[\"other_solution\"] == false_repetition_name and other_catalog_name in other and other[other_catalog_name] == false_repetition_data['page']:\n",
    "                already_added = True\n",
    "                break\n",
    "        if not already_added:\n",
    "            false_repetitions[solution_name][\"others_solutions\"].append({\n",
    "                \"other_solution\": false_repetition_name,\n",
    "                other_catalog_name: false_repetition_data['page']\n",
    "            })\n",
    "    return false_repetitions\n",
    "\n",
    "\n",
    "\"\"\" If there is a solution in other catalog with the exact same solution and company names, it \n",
    "will return True and the solution will be added to the repeated_solutions dictionary. Otherwise, \n",
    "it will return False.\"\"\"\n",
    "def compare_solution_by_name_and_company(solution, catalog_name, catalog_data, other_catalog_name, other_catalog_data, repeated_solutions):\n",
    "    it_was_added = True\n",
    "    if solution in other_catalog_data and catalog_data[solution]['company_url'] == other_catalog_data[solution]['company_url']:\n",
    "        repeated_solutions = add_repeated_solution(solution, repeated_solutions, catalog_name, catalog_data[solution], other_catalog_name, solution, other_catalog_data[solution], 'Name and Company')\n",
    "    else:\n",
    "        it_was_added = False\n",
    "\n",
    "    return repeated_solutions, it_was_added\n",
    "\n",
    "\n",
    "def get_not_common_solutions_types(catalog_name, other_catalog_name, types_association):\n",
    "    not_common_types = []\n",
    "\n",
    "    for association in types_association:\n",
    "        if association[catalog_name] == \"\" and association[other_catalog_name] != \"\":\n",
    "            not_common_types.append(association)\n",
    "    return not_common_types\n",
    "\n",
    "\"\"\"\n",
    "Getting the solution types association for this specific solution. It will return a dictionary \n",
    "with 4 keys (one for each catalog) and the type(s) of the respective catalog. An example for a \n",
    "solution from the Segittur 2022 with Other Hardware / Software Solutions type.\n",
    "{\n",
    "    \"Segittur 2022\": \"Other Hardware / Software Solutions\",\n",
    "    \"Segittur 2023\": \"Other solutions HW / SW\",\n",
    "    \"Adestic V1\": [\n",
    "        \"Software\",\n",
    "        \"POS Software\"\n",
    "    ],\n",
    "    \"Adestic V2\": \"Software\"\n",
    "}\n",
    "If one catalog doesn't have an explicit equivalent solution type, it will return a list of \n",
    "dictionaries with the not common solution types. An example: I want solutions with the \n",
    "Accessibility type from Segittur 2022. The Segittur 2023 doesn't have an explicit equivalent \n",
    "type. \n",
    "{\n",
    "    \"Segittur 2022\": \"Accessibility\",\n",
    "    \"Segittur 2023\": \"\",\n",
    "    \"Adestic V1\": \"Accessibility\",\n",
    "    \"Adestic V2\": \"Accessibility\"\n",
    "}\n",
    "So, the get_possible_equivalent_solutions_types will return:\n",
    "{\n",
    "    \"Segittur 2022\": \"Accessibility\",\n",
    "    \"Segittur 2023\": [{\n",
    "        \"Segittur 2022\": \"\",\n",
    "        \"Segittur 2023\": \"Intelligent Signage/Totems/Tourism Signage\",\n",
    "        \"Adestic V1\": \"\",\n",
    "        \"Adestic V2\": \"\"\n",
    "    }, {...}],\n",
    "    \"Adestic V1\": \"Accessibility\",\n",
    "    \"Adestic V2\": \"Accessibility\"\n",
    "}\n",
    "The value of Segittur 2023 is all the associations of Segittur 2023 where there is not an \n",
    "explicit equivalent solution type with Segittur 2022. This allows me to get all the \n",
    "solutions that may be the same, but are in different categories because they are not all \n",
    "the same between catalogs.\n",
    "\"\"\"\n",
    "def get_possible_equivalent_solutions_types(sol_types, catalog_name, types_association):\n",
    "    for sol_type in sol_types:\n",
    "        for association in types_association:\n",
    "            if (isinstance(association[catalog_name], list) and sol_type in association[catalog_name]) or sol_type == association[catalog_name]:\n",
    "                for key, value in association.items():\n",
    "                    if value == \"\":\n",
    "                        association[key] = get_not_common_solutions_types(catalog_name, key, types_association)\n",
    "                return association\n",
    "    return {}\n",
    "\n",
    "\"\"\" Getting solutions from other catalog that have the same company and an equivalent \n",
    "solution type\"\"\"\n",
    "def get_solutions_from_the_same_company_and_equivalent_type(company, other_catalog_data, other_catalog_name, sol_types_association, filter_by_type):\n",
    "    solutions = {}\n",
    "\n",
    "    # Equivalent solution type of the other catalog from the Type_of_Solution_Association (EN).json file.\n",
    "    sol_type_association = sol_types_association[other_catalog_name]\n",
    "    is_list_of_str_association = isinstance(sol_type_association, list) and all(isinstance(item, str) for item in sol_type_association)\n",
    "    is_list_of_dict_association = isinstance(sol_type_association, list) and all(isinstance(item, dict) for item in sol_type_association)\n",
    "\n",
    "    for other_solution_key, other_solution_value in other_catalog_data.items():\n",
    "        # if other_solution_value['company'] == company:\n",
    "        if other_solution_value['company_url'] == company:\n",
    "            if filter_by_type:\n",
    "                # Solution type of the iterated solution from the other catalog\n",
    "                sol_type = other_solution_value['solType']\n",
    "                is_list_sol_type = isinstance(sol_type, list)\n",
    "    \n",
    "                if is_list_of_str_association and is_list_sol_type and any(element in sol_type_association for element in sol_type):\n",
    "                    solutions[other_solution_key] = other_solution_value\n",
    "                elif (is_list_of_str_association and sol_type in sol_type_association) or (is_list_sol_type and sol_type_association in sol_type):\n",
    "                    solutions[other_solution_key] = other_solution_value\n",
    "                elif sol_type_association == sol_type:\n",
    "                    solutions[other_solution_key] = other_solution_value\n",
    "                elif is_list_of_dict_association:\n",
    "                    for dict_association in sol_type_association:\n",
    "                        if dict_association[other_catalog_name] == sol_type:\n",
    "                            solutions[other_solution_key] = other_solution_value\n",
    "            else:\n",
    "                solutions[other_solution_key] = other_solution_value\n",
    "\n",
    "    return solutions\n",
    "\n",
    "\"\"\" Here, hugchat will be used to compare solutions from the same company and with \n",
    "equivalent solution types. If the solution is identified as a repetition, it will \n",
    "be added to the repeated_solutions dictionary. If it is identified as not being a \n",
    "repetition, it will be added to the false_repetitions dictionary. The aim is for \n",
    "LLM to return a json object with the key repetition and with two possible values: \n",
    "\"YES\" or \"NO\". \n",
    "{\"repetition\": \"YES\"}\n",
    "OR \n",
    "{\"repetition\": \"NO\"}\n",
    "Please note that there may be unforeseen errors and that LLM may not respond as \n",
    "expected. \n",
    "In the first case, if this happens, the program ends and the information about \n",
    "the solution that was being compared is saved (Execution_Data.json) so that next \n",
    "time you can only start comparing from there.  \n",
    "In the second case, which means that the LLM did not return a JSON object with the \n",
    "key repetition and the possible values, this comparison is recorded. Most likely, \n",
    "it won't happen, or it won't happen very often. Therefore, if there is a record, \n",
    "a manual comparison can be made.\n",
    "The prompt template is on Prompt_To_Identfy_Repetitions.txt file. An example of \n",
    "application is on Prompt_To_Identfy_Repetitions_Example.txt file. \n",
    "\"\"\"\n",
    "def compare_descriptions_with_llms(solution_name,solution_data, catalog_name, other_catalog_name, possible_repetitions, repeated_solutions, false_repetitions, wrong_answers):\n",
    "    print(f\"Analysing {len(possible_repetitions.keys())} possible repetitions\")\n",
    "    solution_1 = {\n",
    "        \"title\": solution_name,\n",
    "        \"product_description\": solution_data['product_description'],\n",
    "        \"company\": solution_data['company'],\n",
    "        \"solType\": solution_data['solType']\n",
    "    }\n",
    "    \n",
    "    prompt = open(\"Prompt_To_Identfy_Repetitions.txt\", \"r\", encoding='utf-8').read()\n",
    "    prompt = prompt.replace(\"```SOLUTION 1 ´´´\", json.dumps(solution_1))\n",
    "    \n",
    "    for rep in possible_repetitions:\n",
    "        print(f\"\\tSolution: {rep}\")\n",
    "        solution_2 = {\n",
    "            \"title\": rep,\n",
    "            \"product_description\": possible_repetitions[rep]['product_description'],\n",
    "            \"company\": possible_repetitions[rep]['company'],\n",
    "            \"solType\": possible_repetitions[rep]['solType']\n",
    "        }\n",
    "        new_prompt = prompt.replace(\"```SOLUTION 2 ´´´\", json.dumps(solution_2))\n",
    "        # Sometimes the hugchat chatbot returns an error (\"Exception: Failed to get conversation info with status code: 500\")\n",
    "        try:\n",
    "            query_result = chatbot.chat(new_prompt)\n",
    "            print(f\"\\n\\tQuery result: {query_result}\")\n",
    "        except urllib.error.HTTPError:\n",
    "            print(f\"Internal Server Error\")\n",
    "            return None\n",
    "        except ChatError:\n",
    "            print(f\"Chat Error\")\n",
    "            return None\n",
    "        except Exception:\n",
    "            return None\n",
    "        \n",
    "        match = re.search(r'\\{.*?\\}', query_result.text, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                yes_or_no = json.loads(match.group())\n",
    "                # print(f\"\\t\\tJSON OBJECT: {yes_or_no}\")\n",
    "                if yes_or_no['repetition'].lower() == \"yes\":\n",
    "                    repeated_solutions = add_repeated_solution(solution_name, repeated_solutions, catalog_name, solution_data, other_catalog_name, rep, possible_repetitions[rep], 'LLM')\n",
    "                    print(f\"Repetition identified by LLM\")\n",
    "                elif yes_or_no['repetition'].lower() == \"no\":\n",
    "                    false_repetitions = add_false_repetitions(solution_name, solution_data, rep, possible_repetitions[rep], false_repetitions, catalog_name, other_catalog_name)\n",
    "                    print(f\"Repetition NOT identified by LLM\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Something went wrong on extracting the JSON object in the query result to Solution 1 {solution_name} and Solution 2 {rep}\")\n",
    "        else:\n",
    "            wrong_answers.append([solution_1, solution_2])\n",
    "            print(f\"Something went wrong in the query result to Solution 1 {solution_name} and Solution 2 {rep}\")\n",
    "                \n",
    "    return repeated_solutions, false_repetitions, wrong_answers\n",
    "\n",
    "        \n",
    "def save_results(repeated_solutions, false_repetitions, wrong_answers):\n",
    "    with open(\"Repeated_Solutions.json\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(json.dumps(repeated_solutions, indent=4))\n",
    "    with open(\"False_Repetitions.json\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(json.dumps(false_repetitions, indent=4))\n",
    "    with open(\"Wrong_Answers.json\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(json.dumps(wrong_answers, indent=4))\n",
    "        \n",
    "def save_execution_data_due_to_error(solution_name, catalog_name, other_catalog_name, repeated_solutions, false_repetitions, wrong_answers):\n",
    "    save_results(repeated_solutions, false_repetitions, wrong_answers)\n",
    "    with open(\"Execution_Data.json\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(json.dumps({\n",
    "            \"solution_name\": solution_name,\n",
    "            \"catalog_name\": catalog_name,\n",
    "            \"other_catalog_name\": other_catalog_name\n",
    "        }, indent=4))\n",
    "        \n",
    "def load_json_file_if_exists(file, return_if_doesnt_exist):\n",
    "    if os.path.isfile(file):\n",
    "        return json.load(open(file, 'r', encoding='utf-8'))\n",
    "    else:\n",
    "        return return_if_doesnt_exist\n",
    "        \n",
    "def check_for_repeated_solutions(catalogs, filter_by_type=True):\n",
    "    \"\"\" File path of the information about the solution that was being compared (The \n",
    "    file only if it happened an error the las time). It contains the solution name, \n",
    "    the catalog name and the other catalog name of the last comparison that was \n",
    "    being made.\"\"\"\n",
    "    execution_data_file_path = \"Execution_Data.json\"\n",
    "    \n",
    "    # If there is already repeated solutions saved, it will be loaded. The same for the false repetitions.\n",
    "    repeated_solutions = load_json_file_if_exists(\"Repeated_Solutions.json\", [])\n",
    "    false_repetitions = load_json_file_if_exists(\"False_Repetitions.json\", {})\n",
    "    \n",
    "    # If there are wrong answers from the LLM saved, they will be loaded\n",
    "    wrong_answers = load_json_file_if_exists(\"Wrong_Answers.json\", [])\n",
    "    \n",
    "    # Loading the equivalent solution types among the catalogs\n",
    "    types_association = load_json_file_if_exists(\"Type_of_Solution_Association (EN).json\", {})\n",
    "    \n",
    "    # If the last time the program was interrupted by an error\n",
    "    execution_data = load_json_file_if_exists(execution_data_file_path, {})\n",
    "    \n",
    "    has_reach_the_catalog_saved = False\n",
    "    # Iterate over the catalogs\n",
    "    for i, catalog in enumerate(catalogs):\n",
    "        catalog_name, catalog_data = catalog\n",
    "        \n",
    "        # Checking if there was an error last time and if so, if the current catalog is the same as the one registered\n",
    "        if execution_data != {} and execution_data['catalog_name'] == catalog_name:\n",
    "            has_reach_the_catalog_saved = True\n",
    "            print(f\"Has reached the catalog saved: {catalog_name}\")\n",
    "        elif execution_data != {} and not has_reach_the_catalog_saved:\n",
    "            continue\n",
    "        \n",
    "        if i == len(catalogs) - 1: #All catalogs have been compared\n",
    "            break\n",
    "            \n",
    "        # A list with the remaining catalogs\n",
    "        others_catalogs = catalogs[i+1:]\n",
    "        \n",
    "        has_reach_the_solution_saved = False\n",
    "        # Iterate over the solutions of the current catalog\n",
    "        for solution in catalog_data:\n",
    "            # Checking if there was an error last time and if so, if the current solution is the same as the one registered\n",
    "            if execution_data != {} and execution_data['catalog_name'] == catalog_name:\n",
    "                if execution_data['solution_name'] == solution:\n",
    "                    has_reach_the_solution_saved = True\n",
    "                    print(f\"Has reached the solution saved: {solution}\")\n",
    "                elif not has_reach_the_solution_saved:\n",
    "                    continue\n",
    "                    \n",
    "            print(f\"\\nAnalysing solution: {solution}, page {catalog_data[solution]['page']} from {catalog_name}\")\n",
    "            sol_types_association = get_possible_equivalent_solutions_types(catalog_data[solution]['solType'], catalog_name, types_association)\n",
    "            \n",
    "            has_reach_the_other_catalog_saved = False\n",
    "            \"\"\" If the last time the execution got an error, it is not \n",
    "            necessary to compare by name and company the solution saved \n",
    "            because it failed in the LLM comparasion which is after. \n",
    "            Therefore, when this solution is reached, this variable \n",
    "            (does_it_need_to_compare_by_name_and_company) becomes false \n",
    "            to avoid this step and then returns to true so that the \n",
    "            following solutions perform this step (compare by name and \n",
    "            company)\"\"\"\n",
    "            does_it_need_to_compare_by_name_and_company = True\n",
    "            # Iterate over the other catalogs to find repeated solutions  \n",
    "            for other_catalog_name, other_catalog_data in others_catalogs:\n",
    "                # Checking if the conditions match the last execution when it got an error. If it matches, doesn't need to compare by name and company\n",
    "                if execution_data != {} and execution_data['catalog_name'] == catalog_name and execution_data['solution_name'] == solution:\n",
    "                    if execution_data['other_catalog_name'] == other_catalog_name:\n",
    "                        has_reach_the_other_catalog_saved = True\n",
    "                        print(f\"Has reached the other catalog saved: {other_catalog_name}\")\n",
    "                        does_it_need_to_compare_by_name_and_company = False\n",
    "                    elif not has_reach_the_other_catalog_saved:\n",
    "                            continue\n",
    "                            \n",
    "                if does_it_need_to_compare_by_name_and_company:  \n",
    "                    # Solutions from the same company and with the same name\n",
    "                    repeated_solutions, it_was_added = compare_solution_by_name_and_company(solution, catalog_name, catalog_data, other_catalog_name, other_catalog_data, repeated_solutions)\n",
    "            \n",
    "                    # Move on to the next catalog if a repeated solution was already found in the current other catalog.\n",
    "                    if it_was_added:\n",
    "                        print(f\"Solution found in {other_catalog_name}, by comparing name and company\")\n",
    "                        continue\n",
    "                else:\n",
    "                    # It was already saved the repetitions by name and company the last time the execution got an Exception. The next solution will need to compare by name and company.\n",
    "                    does_it_need_to_compare_by_name_and_company = True\n",
    "                \n",
    "                \"\"\" Solutions from the same company and with compatible solution types. \n",
    "                Then descriptions will be compared to see if they are the same.\"\"\"\n",
    "                # possible_repetitions = get_solutions_from_the_same_company_and_equivalent_type(catalog_data[solution]['company'], other_catalog_data, other_catalog_name, sol_types_association)\n",
    "                possible_repetitions = get_solutions_from_the_same_company_and_equivalent_type(catalog_data[solution]['company_url'], other_catalog_data, other_catalog_name, sol_types_association, filter_by_type)\n",
    "                \n",
    "                if possible_repetitions != {}:\n",
    "                    result = compare_descriptions_with_llms(solution, catalog_data[solution], catalog_name, other_catalog_name, possible_repetitions, repeated_solutions, false_repetitions, wrong_answers)\n",
    "                    if result is None:\n",
    "                        save_execution_data_due_to_error(solution, catalog_name, other_catalog_name, repeated_solutions, false_repetitions, wrong_answers)\n",
    "                        return\n",
    "                    else:\n",
    "                        repeated_solutions, false_repetitions, wrong_answers = result\n",
    "                else:\n",
    "                    print(f\"No possible repetitions found in {other_catalog_name}.\")\n",
    "                    # print(f\"Possible repetitions from {other_catalog_name} of {solution}, with type {catalog_data[solution]['solType']} in {catalog_name}: {json.dumps(possible_repetitions, indent=4)}\")\n",
    "\n",
    "            # This line should be outside the for loop of catalog_data, but inside allows to record the results after iterating a solution and so I have some results saved when I interrupt the execution.\n",
    "            save_results(repeated_solutions, false_repetitions, wrong_answers)\n",
    "        \n",
    "    # The execution data file can be removed after the execution is finished\n",
    "    if os.path.isfile(execution_data_file_path): \n",
    "        os.remove(execution_data_file_path)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21a6d3a98a07cf52"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has reached the catalog saved: Adestic V1\n",
      "Has reached the solution saved: Tracking and Digital Antigen Test\n",
      "\n",
      "Analysing solution: Tracking and Digital Antigen Test, page 26 from Adestic V1\n",
      "Has reached the other catalog saved: Adestic V2\n",
      "Analysing 3 possible repetitions\n",
      "\tSolution: Y Ticketing\n",
      "\n",
      "\tQuery result:              {\n",
      "\t\"repetition\": \"NO\"\n",
      "}\n",
      "\n",
      "These are two distinct solutions with different objectives, solution types, and descriptions.\n",
      "Repetition NOT identified by LLM\n",
      "\tSolution: Yadmin\n",
      "\n",
      "\tQuery result:              {\n",
      "\t\"repetition\": \"NO\"\n",
      "}\n",
      "\n",
      "Based on the provided information, these are two distinct solutions offered by Safety Global. The first solution focuses on tracking and digital antigen tests, while the second solution targets administrative tasks such as appointment scheduling, ticket sales, and capacity management.\n",
      "Repetition NOT identified by LLM\n",
      "\tSolution: YAforo\n",
      "\n",
      "\tQuery result:               {\n",
      "\t\"repetition\": \"NO\"\n",
      "}\n",
      "\n",
      "These two solutions have different focuses, so they cannot be considered the same solution. The first solution, \"Tracking and Digital Antigen Test\" (Rastreocio), offers a customizable QR-based computer application for tracking and performing on-site antigen tests at macro events. The second solution, \"YAforo,\" specializes in capacity control planning, development, and execution for various types of events and places, featuring ERP for ticket sales, consultancy, API integration, and Event Technology components.\n",
      "Repetition NOT identified by LLM\n",
      "\n",
      "Analysing solution: Booking Softme, page 26 from Adestic V1\n",
      "No possible repetitions found in Adestic V2.\n",
      "\n",
      "Analysing solution: Planning Softme, page 27 from Adestic V1\n",
      "No possible repetitions found in Adestic V2.\n",
      "\n",
      "Analysing solution: API Open Data, page 27 from Adestic V1\n",
      "No possible repetitions found in Adestic V2.\n",
      "\n",
      "Analysing solution: DTI Smart Tourism Master Plans, page 28 from Adestic V1\n",
      "Solution found in Adestic V2, by comparing name and company\n",
      "\n",
      "Analysing solution: ICT and Sustainability Improvement Plans, page 28 from Adestic V1\n",
      "Solution found in Adestic V2, by comparing name and company\n",
      "\n",
      "Analysing solution: Technical support for the structuring of tourist experiences and their subsequent communication and marketing, page 29 from Adestic V1\n",
      "Solution found in Adestic V2, by comparing name and company\n",
      "\n",
      "Analysing solution: Tourist Traceability Sensor, page 29 from Adestic V1\n",
      "Solution found in Adestic V2, by comparing name and company\n",
      "\n",
      "Analysing solution: Lora WAN Networks, page 30 from Adestic V1\n",
      "Analysing 1 possible repetitions\n",
      "\tSolution: Tourist Traceability Sensor\n",
      "\n",
      "\tQuery result:               {\n",
      "\t\"repetition\": \"NO\"\n",
      "}\n",
      "\n",
      "These are two separate solutions, although they originate from the same company, SWAT ID. The first one, Lora WAN Networks, focuses on connecting Internet of Things (IoT) sensors in cities with LoRaWAN technology, while the second one, Tourist Traceability Sensor, uses wireless connections to monitor and analyze the presence of mobile devices in certain areas for touristic purposes. Due to their distinct focuses, I would consider these as different solutions.\n",
      "Repetition NOT identified by LLM\n",
      "\n",
      "Analysing solution: IOT Sensorization, page 30 from Adestic V1\n",
      "Analysing 1 possible repetitions\n",
      "\tSolution: Tourist Traceability Sensor\n",
      "\n",
      "\tQuery result:                {\n",
      "\t\"repetition\": \"NO\"\n",
      "}\n",
      "\n",
      "These are two different solutions provided by SWAT ID. Even though they belong to the category of IoT and Sensorization, the focus of each solution varies considerably. Solution 1 covers multiple verticals, such as parking, efficiency, marine buoys, and pollution. Solution 2, named Tourist Traceability Sensor, specifically targets the tourism domain and traces movements using wi-fi, bluetooth, and BLE signals. Based on these observations, I believe these are two distinct solutions.\n",
      "Repetition NOT identified by LLM\n",
      "\n",
      "Analysing solution: Tixalia B2B Tixalia White Label, page 31 from Adestic V1\n",
      "Solution found in Adestic V2, by comparing name and company\n",
      "\n",
      "Analysing solution: Tixalia API, page 31 from Adestic V1\n",
      "Solution found in Adestic V2, by comparing name and company\n",
      "\n",
      "Analysing solution: Tixalia Providers, page 32 from Adestic V1\n",
      "Solution found in Adestic V2, by comparing name and company\n",
      "\n",
      "Analysing solution: Transvia Business Chat, page 32 from Adestic V1\n",
      "No possible repetitions found in Adestic V2.\n",
      "\n",
      "Analysing solution: Transvia Business Booking, page 33 from Adestic V1\n",
      "No possible repetitions found in Adestic V2.\n",
      "\n",
      "Analysing solution: Transvia Onsite, page 33 from Adestic V1\n",
      "No possible repetitions found in Adestic V2.\n",
      "\n",
      "Analysing solution: Smart QR on any medium and space, page 34 from Adestic V1\n",
      "Solution found in Adestic V2, by comparing name and company\n",
      "\n",
      "Analysing solution: Management for spaces and cities, page 34 from Adestic V1\n",
      "Solution found in Adestic V2, by comparing name and company\n",
      "\n",
      "Analysing solution: Qualified data platform, page 35 from Adestic V1\n",
      "Solution found in Adestic V2, by comparing name and company\n"
     ]
    }
   ],
   "source": [
    "#     (\"Segittur 2023\", sol_segittur_2023)\n",
    "#     (\"Adestic V1\", sol_adestic_v1)\n",
    "#     (\"Adestic V2\", sol_adestic_v2)\n",
    "# check_for_repeated_solutions([\n",
    "#     (\"Segittur 2022\", sol_segittur_2022),\n",
    "#     (\"Segittur 2023\", sol_segittur_2023)\n",
    "# ])\n",
    "# check_for_repeated_solutions([\n",
    "#     (\"Segittur 2022\", sol_segittur_2022),\n",
    "#     (\"Adestic V1\", sol_adestic_v1)\n",
    "# ], filter_by_type=False)\n",
    "# check_for_repeated_solutions([\n",
    "#     (\"Segittur 2022\", sol_segittur_2022),\n",
    "#     (\"Adestic V2\", sol_adestic_v2)\n",
    "# ], filter_by_type=False)\n",
    "# check_for_repeated_solutions([\n",
    "#     (\"Segittur 2023\", sol_segittur_2023),\n",
    "#     (\"Adestic V1\", sol_adestic_v1)\n",
    "# ], filter_by_type=False)\n",
    "# check_for_repeated_solutions([\n",
    "#     (\"Segittur 2023\", sol_segittur_2023),\n",
    "#     (\"Adestic V2\", sol_adestic_v2)\n",
    "# ], filter_by_type=False)\n",
    "check_for_repeated_solutions([\n",
    "    (\"Adestic V1\", sol_adestic_v1),\n",
    "    (\"Adestic V2\", sol_adestic_v2)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T11:42:19.446010400Z",
     "start_time": "2024-03-06T11:41:36.545547600Z"
    }
   },
   "id": "10efe8f6665ef35f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Between catalogs of different producers (SEGITTUR and Adestic) there are the same solutions but classified in different ways:\n",
    "    - Infotourist Office from SEGITTUR 2023 (pag. 164) is classified as \"Other solutions HW / SW\"\n",
    "    - Infotourist Office from Adestic V1 (pag. 13) is classified as \"Tourism CRM; Digital marketing; Communication, training or webinar platforms; DTI/Smart City Platform\n",
    "    \n",
    "Besides that, the LLM although it was able to recnognise that the solutions are not exactly the same, sometimes it identified as being the same because in general they do the same but with different applications domains.\n",
    "\n",
    "Examples of that:\n",
    "    {\n",
    "        \"company_url\": \"urbiotica.com\",\n",
    "        \"methods\": [\n",
    "            \"LLM\"\n",
    "        ],\n",
    "        \"Segittur 2022\": [\n",
    "            {\n",
    "                \"solution\": \"FASTPRK: GUIDED PARKING SYSTEM FOR PARK & RIDE CAR PARKS\",\n",
    "                \"page\": 245\n",
    "            },\n",
    "            {\n",
    "                \"solution\": \"FASTPRK: GUIDED PARKING SYSTEM FOR TOURIST BUSES (PARK & RIDE)\",\n",
    "                \"page\": 246\n",
    "            }\n",
    "        ],\n",
    "        \"Segittur 2023\": [\n",
    "            {\n",
    "                \"solution\": \"FASTPRK: GUIDED PARKING SYSTEM FOR PARK & RIDE\\u00a0CAR\\u00a0PARKS\",\n",
    "                \"page\": 341\n",
    "            },\n",
    "            {\n",
    "                \"solution\": \"FASTPRK: GUIDED PARKING SYSTEM FOR TOURIST BUSES (PARK\\u00a0& RIDE)\",\n",
    "                \"page\": 342\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    {\n",
    "        \"company_url\": \"unblockthecity.com\",\n",
    "        \"methods\": [\n",
    "            \"LLM\",\n",
    "            \"Name and Company\"\n",
    "        ],\n",
    "        \"Segittur 2022\": [\n",
    "            {\n",
    "                \"solution\": \"UNBLOCK: THE SMART SIDE OF THE CITY\",\n",
    "                \"page\": 238\n",
    "            }\n",
    "        ],\n",
    "        \"Segittur 2023\": [\n",
    "            {\n",
    "                \"solution\": \"UNBLOCK: THE SMART SIDE OF THE\\u00a0CITY\",\n",
    "                \"page\": 335\n",
    "            }\n",
    "        ],\n",
    "        \"Adestic V1\": [\n",
    "            {\n",
    "                \"solution\": \"Management for spaces and cities\",\n",
    "                \"page\": 34\n",
    "            },\n",
    "            {\n",
    "                \"solution\": \"Smart QR on any medium and space\",\n",
    "                \"page\": 34\n",
    "            },\n",
    "            {\n",
    "                \"solution\": \"Qualified data platform\",\n",
    "                \"page\": 35\n",
    "            }\n",
    "        ],\n",
    "        \"Adestic V2\": [\n",
    "            {\n",
    "                \"solution\": \"Smart QR on any medium and space\",\n",
    "                \"page\": 42\n",
    "            },\n",
    "            {\n",
    "                \"solution\": \"Management for spaces and cities\",\n",
    "                \"page\": 42\n",
    "            },\n",
    "            {\n",
    "                \"solution\": \"Qualified data platform\",\n",
    "                \"page\": 43\n",
    "            }\n",
    "        ]\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0d831b1243549eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4f38dbba22df5398"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
